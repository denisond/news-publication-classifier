{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# import altair as alt\n",
    "# alt.renderers.enable(\"notebook\")\n",
    "\n",
    "# Code for hiding seaborn warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "------------------------------------------------------------\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\test\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downloading punkt and wordnet from NLTK\n",
    "nltk.download('punkt')\n",
    "print(\"------------------------------------------------------------\")\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanish_data_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>year</th>\n",
       "      <th>content</th>\n",
       "      <th>author.1</th>\n",
       "      <th>content_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>162023</td>\n",
       "      <td>Intelligence Official: Transcripts Of Flynn’s ...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>A current U. S. intelligence official tells NP...</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>3010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>172647</td>\n",
       "      <td>After Fatal Police Shooting, Protest Erupts In...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>The police shooting of a man in Charlotte, N. ...</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>5740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>166830</td>\n",
       "      <td>Blasts In Damascus Kill At Least 45; Islamic S...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Three explosions near a shrine revered by Shii...</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>1672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>162911</td>\n",
       "      <td>Head Of USA Gymnastics Resigns Over Group’s Se...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>The president and CEO of USA Gymnastics has re...</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>2548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>172312</td>\n",
       "      <td>WATCH: Bristol Motor Speedway Transformed Into...</td>\n",
       "      <td>NPR</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>It took two decades to arrange a college footb...</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>3101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author      id  \\\n",
       "0  Camila Domonoske  162023   \n",
       "1  Camila Domonoske  172647   \n",
       "2  Camila Domonoske  166830   \n",
       "3  Camila Domonoske  162911   \n",
       "4  Camila Domonoske  172312   \n",
       "\n",
       "                                               title publication    year  \\\n",
       "0  Intelligence Official: Transcripts Of Flynn’s ...         NPR  2017.0   \n",
       "1  After Fatal Police Shooting, Protest Erupts In...         NPR  2016.0   \n",
       "2  Blasts In Damascus Kill At Least 45; Islamic S...         NPR  2016.0   \n",
       "3  Head Of USA Gymnastics Resigns Over Group’s Se...         NPR  2017.0   \n",
       "4  WATCH: Bristol Motor Speedway Transformed Into...         NPR  2016.0   \n",
       "\n",
       "                                             content          author.1  \\\n",
       "0  A current U. S. intelligence official tells NP...  Camila Domonoske   \n",
       "1  The police shooting of a man in Charlotte, N. ...  Camila Domonoske   \n",
       "2  Three explosions near a shrine revered by Shii...  Camila Domonoske   \n",
       "3  The president and CEO of USA Gymnastics has re...  Camila Domonoske   \n",
       "4  It took two decades to arrange a college footb...  Camila Domonoske   \n",
       "\n",
       "   content_len  \n",
       "0         3010  \n",
       "1         5740  \n",
       "2         1672  \n",
       "3         2548  \n",
       "4         3101  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_full'] = df['title'] + ' ' + df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_cleaned_1'] = df['content_full'].str.replace(\"    \", \" \")\n",
    "df['content_cleaned_2'] = df['content_cleaned_1'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation_signs = list(\"?:!.,;…“”'’\\\"\")\n",
    "df['content_cleaned_3'] = df['content_cleaned_2']\n",
    "\n",
    "for punct_sign in punctuation_signs:\n",
    "    df['content_cleaned_3'] = df['content_cleaned_3'].str.replace(punct_sign, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_cleaned_4'] = df['content_cleaned_3'].str.replace(\"'s\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving the lemmatizer into an object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = len(df)\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(nrows):\n",
    "    \n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text = df.loc[row]['content_cleaned_4']\n",
    "    text_words = text.split(\" \")\n",
    "\n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_cleaned_5'] = lemmatized_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Downloading the stop words list\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the stop words in english\n",
    "stop_words = list(stopwords.words('english')) + list(map(lambda x: x.split(' ')[0].lower(), df['author'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_cleaned_6'] = df['content_cleaned_5']\n",
    "for stop_word in stop_words:\n",
    "    regex_stopword = r\"\\b\" + stop_word + r\"\\b\"\n",
    "    df['content_cleaned_6'] = df['content_cleaned_6'].str.replace(regex_stopword, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['content_cleaned_7'] = df['content_cleaned_6']\n",
    "df['content_cleaned_7'] = df['content_cleaned_7'].apply(lambda x: re.sub(\"\\s\\s+\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in range(1,7):\n",
    "#     print(i, df['Content_Parsed_{}'.format(i)].iloc[5], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'listen carrie fisher terry gross — gary dog actress carrie fisher beloved iconic role princess leia die tuesday age 60 leave behind daughter billie lourd brother todd fisher mother debbie reynolds — french bulldog gary gary fisher celebrity right — travel widely fisher star instagram twitter carrie fisher visit nprs studios new york city talk fresh air host terry gross gary come along gross however philadelphia didnt know dog studios didnt even know allow conversation follow impossible miss buoyant personalities fishers — carrie gary ( quick look photos reveal carrie fisher wasnt lie tongue) gross ask dog gary kind famous dog use profile picture twitter hes kind dog fisher french bulldog gross oh ok fisher hes right studio gross yeah get take everywhere like — dont know usually let dog npr studio youre npr bureau new york officially therapy dog fisher yeah — know didnt get hes soothe around hes lick hand right hes nice around gross oh god hear lick hand (laughter) fisher hear gross yes fisher (laughter) gross let listen (soundbite dog licking) fisher (laughter) gross oh god loud lick (laughter) fisher well big tongue gross (laughter) fisher well least wet long tongue gross (laughter) certify therapy dog could like take onto plan things like fisher yes yes sit plane frequently sit chair sit grind gross find fisher get new york village tragic pet store gross fisher look like like puppy mill hes — everything sort wrong gross (laughter) attract fisher tongue — dont even know tongue like first get gradually get longer longer never go mouth gross cant believe still hear lick fisher hes still lick ill put hand hes follow everywhere hes dog ive ever didnt train give high five sit sit like winston churchill gross (laughter) fisher really cant even — see — ill post picture youll see gross (laughter) right carrie fisher thank much talk us fisher well thank talk gross regard dog (laughter) regard gary fisher ill lick hear full interview '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_cleaned_7'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'content_cleaned_7': 'content_cleaned'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content_full</th>\n",
       "      <th>content_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Intelligence Official: Transcripts Of Flynn’s ...</td>\n",
       "      <td>intelligence official transcripts flynns call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>After Fatal Police Shooting, Protest Erupts In...</td>\n",
       "      <td>fatal police shoot protest erupt charlotte nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Blasts In Damascus Kill At Least 45; Islamic S...</td>\n",
       "      <td>blast damascus kill least 45 islamic state cla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Head Of USA Gymnastics Resigns Over Group’s Se...</td>\n",
       "      <td>head usa gymnastics resign group sex abuse sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>WATCH: Bristol Motor Speedway Transformed Into...</td>\n",
       "      <td>watch bristol motor speedway transform vast fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                       content_full  \\\n",
       "0  Camila Domonoske  Intelligence Official: Transcripts Of Flynn’s ...   \n",
       "1  Camila Domonoske  After Fatal Police Shooting, Protest Erupts In...   \n",
       "2  Camila Domonoske  Blasts In Damascus Kill At Least 45; Islamic S...   \n",
       "3  Camila Domonoske  Head Of USA Gymnastics Resigns Over Group’s Se...   \n",
       "4  Camila Domonoske  WATCH: Bristol Motor Speedway Transformed Into...   \n",
       "\n",
       "                                     content_cleaned  \n",
       "0  intelligence official transcripts flynns call ...  \n",
       "1   fatal police shoot protest erupt charlotte nc...  \n",
       "2  blast damascus kill least 45 islamic state cla...  \n",
       "3  head usa gymnastics resign group sex abuse sca...  \n",
       "4  watch bristol motor speedway transform vast fo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_columns = [\"author\", \"content_full\", \"content_cleaned\"]\n",
    "df = df[list_columns]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Camila Domonoske', 'Daniel Nussbaum', 'Jerome Hudson',\n",
       "       'Joel B. Pollak'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.author.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_codes = {\n",
    "    'Camila Domonoske': 0,\n",
    "    'Daniel Nussbaum': 1,\n",
    "    'Jerome Hudson': 2,\n",
    "    'Joel B. Pollak': 3, \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category mapping\n",
    "df['Category_Code'] = df['author']\n",
    "df = df.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content_full</th>\n",
       "      <th>content_cleaned</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Intelligence Official: Transcripts Of Flynn’s ...</td>\n",
       "      <td>intelligence official transcripts flynns call ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>After Fatal Police Shooting, Protest Erupts In...</td>\n",
       "      <td>fatal police shoot protest erupt charlotte nc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Blasts In Damascus Kill At Least 45; Islamic S...</td>\n",
       "      <td>blast damascus kill least 45 islamic state cla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>Head Of USA Gymnastics Resigns Over Group’s Se...</td>\n",
       "      <td>head usa gymnastics resign group sex abuse sca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Camila Domonoske</td>\n",
       "      <td>WATCH: Bristol Motor Speedway Transformed Into...</td>\n",
       "      <td>watch bristol motor speedway transform vast fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                       content_full  \\\n",
       "0  Camila Domonoske  Intelligence Official: Transcripts Of Flynn’s ...   \n",
       "1  Camila Domonoske  After Fatal Police Shooting, Protest Erupts In...   \n",
       "2  Camila Domonoske  Blasts In Damascus Kill At Least 45; Islamic S...   \n",
       "3  Camila Domonoske  Head Of USA Gymnastics Resigns Over Group’s Se...   \n",
       "4  Camila Domonoske  WATCH: Bristol Motor Speedway Transformed Into...   \n",
       "\n",
       "                                     content_cleaned  Category_Code  \n",
       "0  intelligence official transcripts flynns call ...              0  \n",
       "1   fatal police shoot protest erupt charlotte nc...              0  \n",
       "2  blast damascus kill least 45 islamic state cla...              0  \n",
       "3  head usa gymnastics resign group sex abuse sca...              0  \n",
       "4  watch bristol motor speedway transform vast fo...              0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['content_cleaned'], \n",
    "                                                    df['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 300)\n",
      "(300, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "                        \n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Camila Domonoske' category:\n",
      "  . Most correlated unigrams:\n",
      ". clinton\n",
      ". breitbart\n",
      ". trump\n",
      ". associate\n",
      ". report\n",
      "  . Most correlated bigrams:\n",
      ". breitbart news\n",
      ". donald trump\n",
      "\n",
      "# 'Daniel Nussbaum' category:\n",
      "  . Most correlated unigrams:\n",
      ". hollywood\n",
      ". reportedly\n",
      ". film\n",
      ". nussbaum\n",
      ". dznussbaum\n",
      "  . Most correlated bigrams:\n",
      ". twitter dznussbaum\n",
      ". nussbaum twitter\n",
      "\n",
      "# 'Jerome Hudson' category:\n",
      "  . Most correlated unigrams:\n",
      ". black\n",
      ". foundation\n",
      ". 2017\n",
      ". hudson\n",
      ". jeromeehudson\n",
      "  . Most correlated bigrams:\n",
      ". follow hudson\n",
      ". twitter jeromeehudson\n",
      "\n",
      "# 'Joel B. Pollak' category:\n",
      "  . Most correlated unigrams:\n",
      ". available\n",
      ". senior\n",
      ". regnery\n",
      ". pollak\n",
      ". joelpollak\n",
      "  . Most correlated bigrams:\n",
      ". senior breitbart\n",
      ". follow twitter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 300)\n",
      "(300, 300)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "# import seaborn as sns\n",
    "# from matplotlib import pyplot as plt\n",
    "# from scipy import stats\n",
    "# from scipy.stats import mode\n",
    "# from scipy.stats import norm, skew #for some statistics\n",
    "\n",
    "# from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "# from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#ensembles\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.options.display.max_rows=999\n",
    "pd.options.display.max_columns\n",
    "# from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "# from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "# from sklearn.kernel_ridge import KernelRidge\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "# , train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB: 0.911765 (0.023529)\n",
      "LDA: 0.947059 (0.001176)\n",
      "XGB: 0.957647 (0.003529)\n",
      "ScaledLR: 0.955294 (0.001176)\n",
      "ScaledLDA: 0.947059 (0.001176)\n",
      "RobustScaledGBM: 0.957647 (0.001176)\n"
     ]
    }
   ],
   "source": [
    "num_folds = 2\n",
    "seed = 7\n",
    "# scoring = 'accuracy'\n",
    "scoring = 'accuracy'\n",
    "# Standardize the dataset\n",
    "pipelines = []\n",
    "pipelines.append(('AB', AdaBoostClassifier()))\n",
    "# pipelines.append(('ET', ExtraTreesClassifier()))\n",
    "pipelines.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "pipelines.append(('XGB', XGBClassifier()))\n",
    "pipelines.append(('ScaledLR', \n",
    "                  Pipeline([('Scaler', StandardScaler()),\n",
    "                            ('LR',LogisticRegression())])))\n",
    "pipelines.append(('ScaledLDA', \n",
    "                  Pipeline([('Scaler', StandardScaler()),\n",
    "                            ('LDA', LinearDiscriminantAnalysis())])))\n",
    "# pipelines.append(('ScaledKNN', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('KNN', KNeighborsClassifier())])))\n",
    "\n",
    "pipelines.append(('RobustScaledGBM', \n",
    "                  Pipeline([('RobustScaler', RobustScaler()),\n",
    "                            ('GBM', GradientBoostingClassifier())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, features_train, labels_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_folds = 5\n",
    "# seed = 7\n",
    "# # scoring = 'accuracy'\n",
    "# scoring = 'f1_macro'\n",
    "# # Standardize the dataset\n",
    "# pipelines = []\n",
    "# pipelines.append(('AB', AdaBoostClassifier()))\n",
    "# # pipelines.append(('ET', ExtraTreesClassifier()))\n",
    "# pipelines.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# pipelines.append(('XGB', XGBClassifier()))\n",
    "# pipelines.append(('ScaledLR', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LR',LogisticRegression())])))\n",
    "# pipelines.append(('ScaledLDA', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LDA', LinearDiscriminantAnalysis())])))\n",
    "# # pipelines.append(('ScaledKNN', \n",
    "# #                   Pipeline([('Scaler', StandardScaler()),\n",
    "# #                             ('KNN', KNeighborsClassifier())])))\n",
    "\n",
    "# pipelines.append(('RobustScaledGBM', \n",
    "#                   Pipeline([('RobustScaler', RobustScaler()),\n",
    "#                             ('GBM', GradientBoostingClassifier())])))\n",
    "\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in pipelines:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, features_train, labels_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_folds = 5\n",
    "# seed = 7\n",
    "# # scoring = 'accuracy'\n",
    "# scoring = 'precision'\n",
    "# # Standardize the dataset\n",
    "# pipelines = []\n",
    "# pipelines.append(('AB', AdaBoostClassifier()))\n",
    "# # pipelines.append(('ET', ExtraTreesClassifier()))\n",
    "# pipelines.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# pipelines.append(('XGB', XGBClassifier()))\n",
    "# pipelines.append(('ScaledLR', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LR',LogisticRegression())])))\n",
    "# pipelines.append(('ScaledLDA', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LDA', LinearDiscriminantAnalysis())])))\n",
    "# # pipelines.append(('ScaledKNN', \n",
    "# #                   Pipeline([('Scaler', StandardScaler()),\n",
    "# #                             ('KNN', KNeighborsClassifier())])))\n",
    "\n",
    "# pipelines.append(('RobustScaledGBM', \n",
    "#                   Pipeline([('RobustScaler', RobustScaler()),\n",
    "#                             ('GBM', GradientBoostingClassifier())])))\n",
    "\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in pipelines:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, features_train, labels_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_folds = 5\n",
    "# seed = 7\n",
    "# # scoring = 'accuracy'\n",
    "# scoring = 'recall'\n",
    "# # Standardize the dataset\n",
    "# pipelines = []\n",
    "# pipelines.append(('AB', AdaBoostClassifier()))\n",
    "# # pipelines.append(('ET', ExtraTreesClassifier()))\n",
    "# pipelines.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# pipelines.append(('XGB', XGBClassifier()))\n",
    "# pipelines.append(('ScaledLR', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LR',LogisticRegression())])))\n",
    "# pipelines.append(('ScaledLDA', \n",
    "#                   Pipeline([('Scaler', StandardScaler()),\n",
    "#                             ('LDA', LinearDiscriminantAnalysis())])))\n",
    "# # pipelines.append(('ScaledKNN', \n",
    "# #                   Pipeline([('Scaler', StandardScaler()),\n",
    "# #                             ('KNN', KNeighborsClassifier())])))\n",
    "\n",
    "# pipelines.append(('RobustScaledGBM', \n",
    "#                   Pipeline([('RobustScaler', RobustScaler()),\n",
    "#                             ('GBM', GradientBoostingClassifier())])))\n",
    "\n",
    "# results = []\n",
    "# names = []\n",
    "# for name, model in pipelines:\n",
    "#     kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "#     cv_results = cross_val_score(model, features_train, labels_train, cv=kfold, scoring=scoring)\n",
    "#     results.append(cv_results)\n",
    "#     names.append(name)\n",
    "#     msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "#     print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "Be sure to add pub name to stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('doddo')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
